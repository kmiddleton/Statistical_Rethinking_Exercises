---
title: "Chapter 13"
author: "kmm"
date: 'Last updated: `r Sys.Date()`'
output:
  html_document:
    theme: flatly
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rethinking)
library(ellipse)
library(tidyverse)
library(cowplot)
```

## Simulate cafes

```{r}
a <- 3.5
b <- -1
sigma_a <- 1
sigma_b <- 0.5
rho <- -0.7

Mu <- c(a, b)
(sigmas <- c(sigma_a, sigma_b))
(Rho <- matrix(c(1, rho, rho, 1), 2))
(Sigma <- diag(sigmas) %*% Rho %*% diag(sigmas))

N_cafes <- 20

set.seed(5)
vary_effects <- MASS::mvrnorm(N_cafes, Mu, Sigma)

a_cafe <- vary_effects[, 1]
b_cafe <- vary_effects[, 2]

plot(a_cafe, b_cafe, col = rangi2,
     xlab = "intercepts (a_cafe)", ylab = "slopes (b_cafe)")
for (l in c(0.1, 0.3, 0.5, 0.8, 0.99)) {
  lines(ellipse(Sigma, centre = Mu, level = l),
        col = col.alpha("black", 0.2))
}
```

```{r}
N_visits <- 20
afternoon <- rep(0:1, N_visits * N_cafes / 2)
cafe_id <- rep(1:N_cafes, each = N_visits)
mu <- a_cafe[cafe_id] + b_cafe[cafe_id] * afternoon
sigma <- 0.5
wait <- rnorm(N_visits * N_cafes, mu, sigma)
d <- data.frame(cafe = cafe_id, afternoon = afternoon, wait = wait)
```

```{r}
m13.0 <- map2stan(
  alist(
    wait ~ dnorm(mu, sigma),
    mu <- a_cafe[cafe] + b_cafe[cafe] * afternoon,
    a_cafe[cafe] ~ dnorm(0, sigma_cafe),
    b_cafe[cafe] ~ dnorm(0, 10),
    sigma_cafe ~ dcauchy(0, 2),
    sigma ~ dcauchy(0, 2)
  ),
  data = d,
  iter = 5000, warmup = 2000
)
```

```{r}
m13.1 <- map2stan(
  alist(
    wait ~ dnorm(mu, sigma),
    mu <- a_cafe[cafe] + b_cafe[cafe] * afternoon,
    c(a_cafe, b_cafe)[cafe] ~ dmvnorm2(c(a, b), sigma_cafe, Rho),
    a ~ dnorm(0, 10),
    b ~ dnorm(0, 10),
    sigma_cafe ~ dcauchy(0, 2),
    sigma ~ dcauchy(0, 2),
    Rho ~ dlkjcorr(4)
  ),
  data = d,
  iter = 5000, warmup = 2000
)
```

```{r}
rethinking::compare(m13.0, m13.1)
```

```{r}
post <- extract.samples(m13.1)
dens(rlkjcorr(1e5, K = 2, eta = 4)[ , 1, 2], col = "blue",
     ylim = c(0, 2.5))
dens(post$Rho[ , 1, 2], add = TRUE)
```

Compute unpooled estimates directly from data

```{r}
a1 <- sapply(1:N_cafes,
             function(i) mean(wait[cafe_id == i & afternoon == 0]))
b1 <- sapply(1:N_cafes,
             function(i) mean(wait[cafe_id == i & afternoon == 1])) - a1

# extract posterior means of partially pooled estimates
a2 <- apply(post$a_cafe, 2, mean)
b2 <- apply(post$b_cafe, 2, mean)

# Plot both and connect the lines
plot(a1, b1, xlab = "intercept", ylab = "slope",
     pch = 16, col = rangi2,
     ylim = c(min(b1) - 0.1, max(b1) + 0.1),
     xlim = c(min(a1) - 0.1, max(a1) + 0.1))
points(a2, b2, pch = 1)
for (i in 1:N_cafes) lines(c(a1[i], a2[i]), c(b1[i], b2[i]))

# Compute posterior mean bivariate Gaussian
Mu_est <- c(mean(post$a), mean(post$b))
rho_est <- mean(post$Rho[, 1, 2])
sa_est <- mean(post$sigma_cafe[, 1])
sb_est <- mean(post$sigma_cafe[, 2])
cov_ab <- sa_est * sb_est * rho_est
Sigma_est <- matrix(c(sa_est ^ 2, cov_ab, cov_ab, sb_est ^ 2), ncol = 2)
for (l in c(0.1, 0.3, 0.5, 0.8, 0.99)) {
  lines(ellipse(Sigma_est, centre = Mu_est, level = l),
        col = col.alpha("black", 0.2))
}
points(Mu_est[1], Mu_est[2], pch = 16, col = "red")
```

Outcome scale

```{r}
wait_morning_1 <- (a1)
wait_afternoon_1 <- (a1 + b1)
wait_morning_2 <- (a2)
wait_afternoon_2 <- (a1 + b2)

plot(wait_morning_1, wait_afternoon_1,
     pch = 16, col = rangi2)
points(wait_morning_2, wait_afternoon_2, pch = 1)
abline(a = 0, b = 1, lty = "dashed")
for (i in 1:N_cafes) lines(c(wait_morning_1[i], wait_morning_2[i]),
                           c(wait_afternoon_1[i], wait_afternoon_2[i]))
Mu_est <- c(mean(wait_morning_2), mean(wait_afternoon_2))
rho_est <- cor(wait_morning_2, wait_afternoon_2)
sa_est <- sd(wait_morning_2)
sb_est <- sd(wait_afternoon_2)
cov_ab <- sa_est * sb_est * rho_est
Sigma_est <- matrix(c(sa_est ^ 2, cov_ab, cov_ab, sb_est ^ 2), ncol = 2)
for (l in c(0.1, 0.3, 0.5, 0.8, 0.99)) {
  lines(ellipse(Sigma_est, centre = Mu_est, level = l),
        col = col.alpha("black", 0.2))
}

```

## UBC Admits

```{r}
data("UCBadmit")
d <- UCBadmit
d$male <- ifelse(d$applicant.gender == "male", 1, 0)
d$dept_id <- coerce_index(d$dept)

d %>% group_by(dept) %>% mutate(pct = sum(admit) / sum(applications))

d <- d %>% select(-c(applicant.gender, dept))
```

The model `m13.2` with `a` inside `dnorm()` is much better than the model below `m13.2b` with a separate `a` and 0 for `dnorm()`. Much more variance in the latter with `n_eff` much lower. 
The estimate for `a` is the same, regardless. Putting `a` into dnorm rather than 0 generates estimates for `a_dept[i]` that match the observed probabilities quite well, which suggests that these are actual estimates of acceptance rates for each department, drawn from a distribution based on the estimated overall mean, `a`.

Putting `0` in produces estimates that don't make a lot of sense at first glance. These are offsets from the global mean `a`. This seems to be contrary to what is stated on page 399: 

> Remember, the values above are the αDEPT estimates, and so they are deviations from the global mean $\alpha$, which in this case has posterior mean −0.58. So department A, "[1]" in the table, has the highest average admission rate. Department F, "[6]" in the table, has the lowest.).

To recover the value for each department, extract samples from the posterior, calculate the per-department mean, and add the mean value for `a`.

```{r eval=FALSE}
m13.2 <- map2stan(
  alist(
    admit ~ dbinom(applications, p),
    logit(p) <- a_dept[dept_id] + bm * male,
    a_dept[dept_id] ~ dnorm(a, sigma_dept),
    a ~ dnorm(0, 10),
    bm ~ dnorm(0, 1),
    sigma_dept ~ dcauchy(0, 2)
  ),
  data = d,
  warmup = 500, iter = 4500, chains = 4
)
precis(m13.2, depth = 2)
```

```{r eval=FALSE}
m13.2b <- map2stan(
  alist(
    admit ~ dbinom(applications, p),
    logit(p) <- a + a_dept[dept_id] + bm * male,
    a_dept[dept_id] ~ dnorm(0, sigma_dept),
    a ~ dnorm(0, 10),
    bm ~ dnorm(0, 1),
    sigma_dept ~ dcauchy(0, 2)
  ),
  data = d,
  warmup = 500, iter = 4500, chains = 4
)
precis(m13.2b, depth = 2)

# Recover the per-department mean acceptances
post <- extract.samples(m13.2b)
a_dept <- colMeans(post$a_dept) + mean(post$a)
logistic(a_dept)
```

```{r eval=FALSE}
m13.3 <- map2stan(
  alist(
    admit ~ dbinom(applications, p),
    logit(p) <- a_dept[dept_id] + bm_dept[dept_id] * male,
    c(a_dept, bm_dept)[dept_id] ~ dmvnorm2(c(a, bm), sigma_dept, Rho),
    a ~ dnorm(0, 10),
    bm ~ dnorm(0, 1),
    sigma_dept ~ dcauchy(0, 2),
    Rho ~ dlkjcorr(2)
  ),
  data = d,
  warmup = 2000, iter = 5000, chains = 4
)
precis(m13.3, depth = 2)
```

```{r eval=FALSE}
plot(precis(m13.3, pars = c("a_dept", "bm_dept"), depth = 2))
post <- extract.samples(m13.3)
dens(post$Rho[, 1, 2])
```

## Cross-classified chimpanzees

```{r eval=FALSE}
data("chimpanzees")
d <- chimpanzees %>% 
  select(-recipient) %>% 
  rename(block_id = block) %>% 
  as.data.frame()

m13.6 <- map2stan(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) <- A + (BP + BPC * condition) * prosoc_left,
    A <- a + a_actor[actor] + a_block[block_id],
    BP <- bp * bp_actor[actor] + bp_block[block_id],
    BPC <- bpc * bpc_actor[actor] + bpc_block[block_id],
    c(a_actor, bp_actor, bpc_actor)[actor] ~ 
      dmvnorm2(0, sigma_actor, Rho_actor),
    c(a_block, bp_block, bpc_block)[block_id] ~ 
      dmvnorm2(0, sigma_block, Rho_block),
    c(a, bp, bpc) ~ dnorm(0, 1),
    sigma_actor ~ dcauchy(0, 2),
    sigma_block ~ dcauchy(0, 2),
    Rho_actor ~ dlkjcorr(2),
    Rho_block ~ dlkjcorr(2)
  ),
  data = d, iter = 10000, warmup = 1000, chains = 4, cores = 4
)

m13.6NC <- map2stan(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) <- A + (BP + BPC * condition) * prosoc_left,
    A <- a + a_actor[actor] + a_block[block_id],
    BP <- bp * bp_actor[actor] + bp_block[block_id],
    BPC <- bpc * bpc_actor[actor] + bpc_block[block_id],
    c(a_actor, bp_actor, bpc_actor)[actor] ~ 
      dmvnormNC(sigma_actor, Rho_actor),
    c(a_block, bp_block, bpc_block)[block_id] ~ 
      dmvnormNC(sigma_block, Rho_block),
    c(a, bp, bpc) ~ dnorm(0, 1),
    sigma_actor ~ dcauchy(0, 2),
    sigma_block ~ dcauchy(0, 2),
    Rho_actor ~ dlkjcorr(2),
    Rho_block ~ dlkjcorr(2)
  ),
  data = d, iter = 10000, warmup = 1000, chains = 4, cores = 4
)
```

```{r eval=FALSE}
precis(m13.6)
precis(m13.6NC)
rethinking::compare(m13.6, m13.6NC)
```

## Spatial autocorrelation in oceanic tools

```{r}
data("islandsDistMatrix")
Dmat <- islandsDistMatrix
Dmat <- round(Dmat, 1)

data("Kline2")
d <- Kline2
d$society <- 1:10

m13.7 <- map2stan(
  alist(
    total_tools ~ dpois(lambda),
    log(lambda) <- a + g[society] + bp * logpop,
    g[society] ~ GPL2(Dmat, etasq, rhosq, 0.01),
    a ~ dnorm(0, 10),
    bp ~ dnorm(0, 1),
    etasq ~ dcauchy(0, 1),
    rhosq ~ dcauchy(0, 1)
  ),
  data = list(
    total_tools = d$total_tools,
    logpop = d$logpop,
    society = d$society,
    Dmat = islandsDistMatrix
  ),
  warmup = 2000,
  iter = 1e4
)
precis(m13.7, depth = 2)
post <- extract.samples(m13.7)
dens(post$g)
```

